name: Linux UT Test

on:
  workflow_call:
    inputs:
      pytorch:
        required: false
        type: string
        default: 'main'
        description: Pytorch branch/commit
      keep_torch_xpu_ops:
        required: false
        type: string
        default: 'false'
        description: Keep torch-xpu-ops pin. `true` means use pined commit
      ut:
        required: true
        type: string
        default: ''
        description: UT scope. `op_example,op_extended,op_ut,torch_xpu` Delimiter is comma
      python:
        required: false
        type: string
        default: '3.10'
        description: Python version
      runner:
        required: true
        type: string
        default: 'linux.idc.xpu'
        description: Runner label
      expected_fail_num:
        required: false
        type: string
        default: ''
        description: Set expected failed number for UT



jobs:
  Torch-XPU-UT-Tests:
    runs-on: ${{ inputs.runner }} 
    timeout-minutes: 900
    steps:
      - name: Checkout torch-xpu-ops
        uses: actions/checkout@v4
      - name: Prepare Stock Pytorch
        run: |
          pwd
          which conda && conda clean -ay
          conda remove --all -y -n xpu_op_${ZE_AFFINITY_MASK} || \
                rm -rf $(dirname ${CONDA_EXE})/../envs/xpu_op_${ZE_AFFINITY_MASK}
          conda create -n xpu_op_${ZE_AFFINITY_MASK} python=${{ inputs.python }} cmake ninja -y
          source activate xpu_op_${ZE_AFFINITY_MASK}
          cd ../ && rm -rf pytorch
          git clone https://github.com/pytorch/pytorch pytorch
          cd pytorch && git checkout ${{ inputs.pytorch }} 
          # apply PRs for stock pytorch
          pip install requests
          python ../torch-xpu-ops/.github/scripts/apply_torch_pr.py
          git status && git show -s
          git submodule sync && git submodule update --init --recursive
          if [[ ${{ inputs.keep_torch_xpu_ops }} == 'true' ]]; then
            echo "Don't replace torch-xpu-ops!"
          else
            rm -rf third_party/torch-xpu-ops && cp -r ../torch-xpu-ops third_party/
            # Workaround for torch-xpu-ops ci test
            sed -i "s/checkout --quiet \${TORCH_XPU_OPS_COMMIT}/log -n 1/g" caffe2/CMakeLists.txt
          fi
      - name: Build Pytorch XPU
        run: |
          source activate xpu_op_${ZE_AFFINITY_MASK}
          conda install -c intel mkl-static mkl-include -y
          cd ../pytorch
          pip install -r requirements.txt
          export USE_XPU=1
          source /opt/intel/oneapi/pytorch-gpu-dev-0.5/oneapi-vars.sh
          export CMAKE_PREFIX_PATH=${CONDA_PREFIX:-"$(dirname $(which conda))/../"}
          WERROR=1 python setup.py bdist_wheel
          pip install --force-reinstall dist/*.whl
          git clone https://github.com/pytorch/vision && cd vision && python setup.py install && cd ..
          pip install -r .ci/docker/requirements-ci.txt
      - name: Run XPU OP Examples
        if: contains(inputs.ut, 'op_example') || github.event_name == 'schedule'
        run: |
          cd ${{ github.workspace }}
          xpu-smi discovery
          source /opt/intel/oneapi/pytorch-gpu-dev-0.5/oneapi-vars.sh
          source activate xpu_op_${ZE_AFFINITY_MASK}
          cd ${{ github.workspace }}
          mkdir -p ut_log
          cd examples
          pip install pytest
          timeout 8000 pytest -v 2>&1 | tee ${{ github.workspace }}/ut_log/op_example_test.log
      - name: Run XPU OP Extended UT
        if: contains(inputs.ut, 'op_extended') || github.event_name == 'schedule'
        run: |
          source /opt/intel/oneapi/pytorch-gpu-dev-0.5/oneapi-vars.sh
          source activate xpu_op_${ZE_AFFINITY_MASK}
          export PYTORCH_TEST_WITH_SLOW=1
          cd ../pytorch/third_party/torch-xpu-ops/test/xpu/extended/
          timeout 10000 python run_test_with_skip.py 2>&1 | tee ${{ github.workspace }}/ut_log/op_extended_test.log
      - name: Run XPU OP UT
        if: contains(inputs.ut, 'op_ut') || github.event_name == 'schedule'
        run: |
          source /opt/intel/oneapi/pytorch-gpu-dev-0.5/oneapi-vars.sh
          source activate xpu_op_${ZE_AFFINITY_MASK}
          export PYTORCH_ENABLE_XPU_FALLBACK=1
          export PYTORCH_TEST_WITH_SLOW=1
          cd ../pytorch/third_party/torch-xpu-ops/test/xpu
          timeout 10000 python run_test_with_skip.py 2>&1 | tee ${{ github.workspace }}/ut_log/op_ut_with_skip_test.log
          # Cases run with a on-demand white list, since some suites are too
          # slow to go through all operators on CPU. So add cases on-demand
          # when XPU implementatoin is done.
          # test_foreach, test_decomp
          timeout 10000 python run_test_with_only.py 2>&1 | tee ${{ github.workspace }}/ut_log/op_ut_with_only_test.log
      - name: Run Torch XPU UT
        if: contains(inputs.ut, 'torch_xpu') || github.event_name == 'schedule'
        run: |
          source /opt/intel/oneapi/pytorch-gpu-dev-0.5/oneapi-vars.sh
          source activate xpu_op_${ZE_AFFINITY_MASK}
          cd ../pytorch
          TEST_REPORTS_DIR=$(pwd)/test/test-reports
          rm -rf "$TEST_REPORTS_DIR" && mkdir -p "$TEST_REPORTS_DIR"
          # Run Pytorch XPU binary UT
          for xpu_case in build/bin/*{xpu,sycl}*; do
            if [[ "$xpu_case" != *"*"* && "$xpu_case" != *.so && "$xpu_case" != *.a ]]; then
              case_name=$(basename "$xpu_case")
              echo "Testing ${case_name} ..."
              "$xpu_case" --gtest_output=xml:"$TEST_REPORTS_DIR"/"$case_name".xml 2>&1 | tee ${{ github.workspace }}/ut_log/binary_UT_${ut_suite}_${case_name}_Test.log
            fi
          done
          # Run Pytorch XPU python UT
          export PYTORCH_TEST_WITH_SLOW=1
          export PYTORCH_TESTING_DEVICE_ONLY_FOR="xpu"

          test_cmd="python test/run_test.py --include "
          # All Inductor UT under test/inductor
          for test in $(ls test/inductor | grep test);
          do 
              test_cmd="${test_cmd} inductor/$test";
          done
          # All xpu ut under test/xpu
          for test in $(ls test/xpu | grep test);
          do 
              test_cmd="${test_cmd} xpu/$test";
          done
          if [ -f "test/test_xpu.py" ]; then
            test_cmd="${test_cmd} test_xpu.py"
          fi
          eval $test_cmd

      - name: Upload Inductor XPU UT Data
        uses: actions/upload-artifact@v4
        with:
          name: Inductor-XPU-UT-Data-${{ github.event.pull_request.number || github.sha }}
          path: ${{ github.workspace }}/ut_log

      - name: UT Test Results Check
        if: ${{ inputs.expected_fail_num }}
        shell: bash
        run: |
          # check param
          function contains() {
              contains_status="echo 'Start $2 ...'"
              {
                [[ $1 =~ (^|,)$2($|,) ]]
              } || {
                echo "[Warning] $2 is not suppotted type! Skipped!"
                contains_status="continue"
              }
          }
          set -xe
          for ut_suite in $(echo ${{ inputs.ut_suite }} |sed 's/,/ /g')
          do
            contains "op_example,op_extended,op_ut,torch_xpu" $ut_suite
            $contains_status
            cd ${{ github.workspace }}/ut_log
            if [[ ${ut_suite} == 'op_example' || ${ut_suite} == 'op_extended' ]]; then
              grep "^FAILED" ${ut_suite}_test.log | awk '{print $2}' > ./${ut_suite}_failed.log
              grep "PASSED" ${ut_suite}_test.log | awk '{print $1}' > ./${ut_suite}_passed.log
              num_failed=$(cat ./${ut_suite}_failed.log | wc -l)
              num_passed=$(cat ./${ut_suite}_passed.log | wc -l)
              if [[ $num_failed -gt ${{ inputs.expected_fail_num }} ]] && [[ $num_passed -lt 0 ]]; then
                echo -e "[ERROR] Inductor UT ${ut_suite} test Fail"
                exit 1
              fi
            fi
            if [[ ${ut_suite} == 'op_ut' ]]; then
              grep "^FAILED" XPU_OP_with_skip_UT_Test.log | awk '{print $2}' > ./${ut_suite}_with_skip_test.log
              grep "^FAILED" XPU_OP_with_only_UT_Test.log | awk '{print $2}' > ./${ut_suite}_with_only_test.log
              num_failed_with_skip=$(cat ./${ut_suite}_with_skip_test.log | wc -l)
              num_failed_with_only=$(cat ./${ut_suite}_with_only_test.log | wc -l)
              let num_failed=num_failed_with_skip+num_failed_with_only
              grep "PASSED" XPU_OP_with_skip_UT_Test.log | awk '{print $1}' > ./${ut_suite}_with_skip_passed.log
              grep "PASSED" XPU_OP_with_only_UT_Test.log | awk '{print $1}' > ./${ut_suite}_with_only_passed.log
              num_passed_with_skip=$(cat ./${ut_suite}_with_skip_passed.log | wc -l)
              num_passed_with_only=$(cat ./${ut_suite}_with_only_passed.log | wc -l)
              let num_passed=num_passed_with_skip+num_passed_with_only
              if [[ $num_failed -gt ${{ inputs.expected_fail_num }} ]] && [[ $num_passed -lt 0 ]]; then
                echo -e "[ERROR] Inductor UT ${ut_suite} test Fail"
                exit 1
              fi
            fi
            if [[ ${ut_suite} == 'torch_xpu' ]]; then
              echo "Pytorch XPU binary UT checking"
              cd ${{ github.workspace }}
              cd ../pytorch
              TEST_REPORTS_DIR=$(pwd)/test/test-reports
              for xpu_case in build/bin/*{xpu,sycl}*; do
                if [[ "$xpu_case" != *"*"* && "$xpu_case" != *.so && "$xpu_case" != *.a ]]; then
                  case_name=$(basename "$xpu_case")
                  echo "Checking ${case_name} ..."
                  cd ${{ github.workspace }}/ut_log
                  grep -E "FAILED" binary_UT_${ut_suite}_${case_name}_Test.log | awk '{print $2}' > ./binary_UT_${ut_suite}_${case_name}_failed.log
                  echo $(cat ./binary_UT_${ut_suite}_${case_name}_failed.log | wc -l) | tee -a ./binary_UT_${ut_suite}_failed_summary.log
                  grep -E "PASSED|Pass" binary_UT_${ut_suite}_${case_name}_Test.log | awk '{print $2}' > ./binary_UT_${ut_suite}_${case_name}_passed.log
                  echo $(cat ./binary_UT_${ut_suite}_${case_name}_passed.log | wc -l) | tee -a ./binary_UT_${ut_suite}_passed_summary.log
                fi
              done
              num_failed_binary_UT=$(awk '{sum += $1};END {print sum}' binary_UT_${ut_suite}_failed_summary.log)
              num_passed_binary_UT=$(awk '{sum += $1};END {print sum}' binary_UT_${ut_suite}_passed_summary.log)
              let num_failed=num_failed_binary_UT
              if if [[ $num_failed -gt ${{ inputs.expected_fail_num }} ]] && [[ $num_passed_binary_UT -lt 0 ]]; then
                echo -e "[ERROR] Inductor UT ${ut_suite} test Fail"
                exit 1
              fi
            fi
          done
