diff --git a/torch/testing/_internal/common_device_type.py b/torch/testing/_internal/common_device_type.py
index 07caa0ac3ee..53944351689 100644
--- a/torch/testing/_internal/common_device_type.py
+++ b/torch/testing/_internal/common_device_type.py
@@ -1082,7 +1082,7 @@ def _has_sufficient_memory(device, size):
         if device == 'cuda':
             device = 'cuda:0'
         return torch.cuda.memory.mem_get_info(device)[0] >= size
-
+   
     if device == 'xla':
         raise unittest.SkipTest('TODO: Memory availability checks for XLA?')
 
@@ -1584,4 +1584,9 @@ def skipPRIVATEUSE1(fn):
 # TODO: the "all" in the name isn't true anymore for quite some time as we have also have for example XLA and MPS now.
 #  This should probably enumerate all available device type test base classes.
 def get_all_device_types() -> List[str]:
-    return ['cpu'] if not torch.cuda.is_available() else ['cpu', 'cuda']
+    devices = ['cpu',]
+    if torch.cuda.is_available():
+        devices.append('cuda')
+    if torch.xpu.is_available():
+        devices.append('xpu')
+    return devices
diff --git a/torch/testing/_internal/common_utils.py b/torch/testing/_internal/common_utils.py
index af5dcf35b4a..43b0d9b763b 100644
--- a/torch/testing/_internal/common_utils.py
+++ b/torch/testing/_internal/common_utils.py
@@ -227,7 +227,7 @@ if os.getenv("SLOW_TESTS_FILE", ""):
 if os.getenv("DISABLED_TESTS_FILE", ""):
     disabled_tests_dict = maybe_load_json(os.getenv("DISABLED_TESTS_FILE", ""))
 
-NATIVE_DEVICES = ('cpu', 'cuda', 'meta', torch._C._get_privateuse1_backend_name())
+NATIVE_DEVICES = ('cpu', 'cuda', 'meta', 'xpu', torch._C._get_privateuse1_backend_name())
 
 check_names = ['orin', 'concord', 'galen', 'xavier', 'nano', 'jetson', 'tegra']
 IS_JETSON = any(name in platform.platform() for name in check_names)
@@ -1494,6 +1494,8 @@ def disable_translation_validation_if_dynamic_shapes(fn):
 # See: https://github.com/pytorch/pytorch/pull/59402#issuecomment-858811135
 TestEnvironment.def_flag("TEST_CUDA_MEM_LEAK_CHECK", env_var="PYTORCH_TEST_CUDA_MEM_LEAK_CHECK")
 
+TestEnvironment.def_flag("TEST_XPU_MEM_LEAK_CHECK", env_var="PYTORCH_TEST_XPU_MEM_LEAK_CHECK")
+
 # True if CI is running TBB-enabled Pytorch
 IS_TBB = "tbb" in os.getenv("BUILD_ENVIRONMENT", "")
 
@@ -2611,6 +2613,14 @@ class TestCase(expecttest.TestCase):
                 print(str(rte), file=sys.stderr)
                 return True
             return False
+        elif torch.xpu.is_initialized():
+            try:
+                torch.xpu.synchronize()
+            except RuntimeError as rte:
+                print("TEST SUITE EARLY TERMINATION due to torch.xpu.synchronize() failure", file=sys.stderr)
+                print(str(rte), file=sys.stderr)
+                return True
+            return False
         else:
             return False
 
@@ -2732,8 +2742,9 @@ This message can be suppressed by setting PYTORCH_PRINT_REPRO_ON_FAILURE=0"""
         # TODO: sure looks like we unconditionally initialize the context here
         # -- ezyang
         from torch.testing._internal.common_cuda import TEST_CUDA
+        from torch.testing._internal.common_utils import TEST_XPU
         fullname = self.id().lower()  # class_name.method_name
-        if TEST_CUDA and ('gpu' in fullname or 'cuda' in fullname):
+        if (TEST_CUDA and ('gpu' in fullname or 'cuda' in fullname)) or (TEST_XPU and ('gpu' in fullname or 'cuda' in fullname)):
             setattr(self, method_name, self.wrap_method_with_policy(test_method, policy))
 
     def wrap_with_policy(self, method_name, policy):
